# QVF Orchestration System

Enterprise-grade orchestration engine for QVF (Quantified Value Framework) scoring operations, designed to handle 10,000+ work items with <60 second full portfolio recalculation.

## üéØ Overview

The QVF Orchestration System provides comprehensive coordination of scoring operations including:

- **Real-time and batch processing** with intelligent mode selection
- **Priority-based scheduling** with cron-like job management  
- **Resource-aware throttling** to prevent system overload
- **Comprehensive monitoring** with alerting and performance analytics
- **Error recovery and retry logic** for enterprise reliability
- **Data consistency guarantees** with transaction management

## üèóÔ∏è Architecture

```
QVF Orchestration System
‚îú‚îÄ‚îÄ QVFOrchestrator          # Main coordination engine
‚îú‚îÄ‚îÄ ScoringWorkflow          # Individual workflow management
‚îú‚îÄ‚îÄ BatchProcessor           # High-performance batch processing
‚îú‚îÄ‚îÄ QVFScheduler             # Job scheduling and queue management
‚îú‚îÄ‚îÄ ResourceMonitor          # System resource monitoring
‚îú‚îÄ‚îÄ OperationMonitor         # Metrics collection and alerting
‚îî‚îÄ‚îÄ AlertManager             # Alert management and notifications
```

### Core Components

#### 1. QVFOrchestrator
**Primary coordination engine for all QVF operations**

```python
orchestrator = QVFOrchestrator(
    organization_url="https://dev.azure.com/yourorg",
    personal_access_token="your_pat",
    batch_size=100,
    max_concurrent_workflows=5
)

# Real-time scoring
result = await orchestrator.score_work_items(
    project_name="Enterprise",
    work_item_ids=[1234, 5678],
    mode=ScoringMode.REAL_TIME
)
```

**Key Features:**
- Supports all scoring modes (real-time, batch, incremental, full recalculation)
- Intelligent workflow routing and load balancing
- Comprehensive error handling with graceful degradation
- Integration with all QVF components (scoring, ADO, AI)

#### 2. QVFScheduler
**Advanced scheduling with priority queue management**

```python
scheduler = QVFScheduler()

# Schedule recurring batch scoring
job_id = await scheduler.schedule_job(
    job_name="Daily Portfolio Update",
    job_type=JobType.BATCH_SCORING,
    cron_expression="0 2 * * *",  # Daily at 2 AM
    project_name="Enterprise",
    configuration=qvf_config
)

# Queue high-priority request
request_id = await scheduler.queue_priority_request(
    scoring_request=request,
    priority=Priority.HIGH,
    max_wait_seconds=30
)
```

**Key Features:**
- Cron-based scheduling for recurring operations
- Priority queue with SLA guarantees
- Resource-aware job scheduling
- Dead letter queue for failed jobs with retry logic
- Job dependency management

#### 3. OperationMonitor
**Comprehensive monitoring and performance analytics**

```python
monitor = OperationMonitor(enable_real_time_alerts=True)

# Track operation with context manager
with monitor.track_operation("batch_scoring") as tracker:
    result = await orchestrator.score_work_items(...)
    tracker.record_success(result.successful_updates)
    tracker.record_performance_metrics(result.performance_metrics)

# Get comprehensive metrics
metrics = monitor.get_comprehensive_metrics(
    time_range=timedelta(hours=24)
)
```

**Key Features:**
- Real-time operation tracking with sub-millisecond recording
- Time-series metrics storage with automatic compression
- Automated anomaly detection and intelligent alerting
- Performance analysis with optimization recommendations

## üöÄ Quick Start

### Basic Setup

```python
from datascience_platform.qvf.orchestration import QVFOrchestrator, ScoringMode
from datascience_platform.qvf.core.criteria import create_default_qvf_configuration

# Initialize orchestrator
orchestrator = QVFOrchestrator(
    organization_url="https://dev.azure.com/yourorg",
    personal_access_token="your_pat"
)

# Create QVF configuration
qvf_config = create_default_qvf_configuration()

# Score work items
async with orchestrator:
    result = await orchestrator.score_work_items(
        project_name="MyProject",
        mode=ScoringMode.BATCH,
        criteria_config=qvf_config
    )
    
    print(f"Processed {result.total_items_processed} items")
    print(f"Success rate: {result.success_rate:.1f}%")
```

### Advanced Configuration

```python
from datascience_platform.qvf.orchestration import (
    QVFOrchestrator, QVFScheduler, OperationMonitor
)

# Configure orchestrator with monitoring
orchestrator = QVFOrchestrator(
    organization_url="https://dev.azure.com/yourorg",
    personal_access_token="your_pat",
    batch_size=500,
    max_concurrent_workflows=10,
    enable_ai_enhancement=True
)

# Setup monitoring
monitor = OperationMonitor(enable_real_time_alerts=True)
await monitor.start_background_tasks()

# Setup scheduler
scheduler = QVFScheduler(
    resource_limits=ResourceLimits(
        max_cpu_percent=80.0,
        max_memory_percent=85.0,
        max_concurrent_workflows=10
    )
)
```

## üìã Operation Modes

### Real-Time Scoring
For immediate scoring of individual work items or small sets:

```python
result = await orchestrator.score_work_items(
    project_name="Enterprise",
    work_item_ids=[1234, 5678, 9012],
    mode=ScoringMode.REAL_TIME,
    priority=OperationPriority.HIGH
)
# Typical completion: <2 seconds
```

### Batch Scoring
For processing large sets of work items efficiently:

```python
result = await orchestrator.batch_score_all_items(
    project_name="Enterprise",
    criteria_config=qvf_config,
    batch_size=500
)
# Handles 10,000+ items in <60 seconds
```

### Incremental Updates
For processing only changed work items:

```python
result = await orchestrator.incremental_update(
    project_name="Enterprise", 
    criteria_config=qvf_config,
    changed_since=datetime.now() - timedelta(hours=24)
)
```

### Scheduled Operations
For recurring processing with cron-like scheduling:

```python
job_id = await scheduler.schedule_job(
    job_name="Nightly Portfolio Update",
    job_type=JobType.BATCH_SCORING,
    cron_expression="0 2 * * *",  # Daily at 2 AM
    project_name="Enterprise",
    configuration={
        "mode": ScoringMode.BATCH.value,
        "batch_size": 1000
    }
)
```

## üìä Performance Specifications

### Throughput
- **Real-time**: <2 second response for individual items
- **Batch**: 80+ items/second for large datasets
- **Enterprise scale**: 10,000+ items in <60 seconds

### Reliability
- **Success rate**: 95%+ under normal conditions
- **Error recovery**: Automatic retry with exponential backoff
- **Data consistency**: ACID-like guarantees for score updates
- **Failover**: <2 second failover for high-priority requests

### Resource Efficiency
- **Memory usage**: <100MB for 10,000 items
- **CPU utilization**: Adaptive based on system load
- **API rate limiting**: Configurable limits with backpressure
- **Concurrent operations**: Up to 10 workflows simultaneously

### Scalability
- **Horizontal scaling**: Multi-instance deployment ready
- **Queue capacity**: 10,000+ pending operations
- **Time-series storage**: Millions of metric points
- **Alert processing**: Real-time with <1 second latency

## üîß Configuration Options

### Resource Limits
```python
resource_limits = ResourceLimits(
    max_cpu_percent=80.0,         # CPU usage limit
    max_memory_percent=85.0,      # Memory usage limit  
    max_concurrent_workflows=10,   # Concurrent workflow limit
    max_api_calls_per_minute=1000, # API rate limit
    max_queue_size=10000          # Priority queue size limit
)
```

### Scoring Configuration
```python
scoring_config = ScoringConfiguration(
    integration_mode=IntegrationMode.BALANCED,
    financial_weight=0.4,
    strategic_weight=0.6,
    enable_dynamic_normalization=True,
    risk_adjustment_enabled=True
)
```

### Monitoring Configuration
```python
monitor = OperationMonitor(
    max_operation_history=10000,    # Operations to keep in memory
    enable_real_time_alerts=True,   # Real-time alerting
    metric_retention_days=30        # Days to retain detailed metrics
)
```

## üö® Alerting and Monitoring

### Default Alert Rules
The system includes pre-configured alerts for common issues:

- **Low Success Rate**: <90% success rate (Warning), <75% (Critical)
- **Low Throughput**: <1 item/second processing rate
- **Data Quality Issues**: Data quality score <0.7
- **Resource Constraints**: CPU >80%, Memory >85%

### Custom Alert Rules
```python
monitor._alert_manager.add_alert_rule(
    rule_name="custom_performance_alert",
    metric_name="items_per_second",
    threshold_value=5.0,
    comparison_operator="lt",
    severity=AlertSeverity.WARNING,
    description="Processing rate below 5 items/second"
)
```

### Alert Callbacks
```python
def alert_handler(alert):
    print(f"ALERT: {alert.title} - {alert.description}")
    # Send to external monitoring system
    send_to_slack(alert)
    send_to_pagerduty(alert)

monitor.add_alert_callback(alert_handler)
```

## üîÑ Workflow Management

### Workflow Status Tracking
```python
# Get active workflows
active_workflows = orchestrator.get_active_workflows()

# Get workflow history
recent_workflows = orchestrator.get_workflow_history(limit=50)

# Get detailed workflow information
workflow_details = monitor.get_operation_details("workflow_12345")
```

### Workflow Cancellation
```python
# Cancel active workflow
for workflow in orchestrator.get_active_workflows():
    if workflow["project_name"] == "TestProject":
        # Workflows are cancelled automatically when orchestrator is stopped
        break
```

### Progress Tracking
```python
def progress_callback(stage, progress, message):
    print(f"{stage}: {progress*100:.1f}% - {message}")

result = await orchestrator.score_work_items(
    project_name="Enterprise",
    mode=ScoringMode.BATCH,
    criteria_config=qvf_config,
    progress_callback=progress_callback
)
```

## üîê Security and Compliance

### Authentication
- Azure DevOps Personal Access Token (PAT) authentication
- Secure token storage and rotation support
- Role-based access control (RBAC) ready

### Data Privacy
- No sensitive data stored in logs
- Configurable data retention policies
- GDPR/CCPA compliance features

### Audit Trail
- Comprehensive operation logging
- Score change history tracking
- User activity monitoring
- Compliance reporting capabilities

## üõ†Ô∏è Troubleshooting

### Common Issues

#### Performance Issues
```python
# Check system health
health_report = await orchestrator.validate_system_health("MyProject")
print(f"System health: {health_report['overall_health']}")

# Review performance metrics
metrics = monitor.get_comprehensive_metrics(timedelta(hours=1))
print(f"Average throughput: {metrics['quality_metrics']['average_throughput']}")
```

#### Error Investigation
```python
# Get recent errors from operation history
recent_ops = monitor.get_workflow_history(limit=10)
failed_ops = [op for op in recent_ops if op.status == WorkflowStatus.FAILED]

for op in failed_ops:
    print(f"Failed operation {op.workflow_id}: {op.errors}")
```

#### Resource Constraints
```python
# Check resource usage
stats = orchestrator.get_operation_statistics()
resource_status = stats["batch_processor"]

if resource_status["active_batches"] >= resource_status["max_concurrent"]:
    print("System at capacity - consider increasing limits")
```

### Debugging Tips

1. **Enable verbose logging** for detailed operation traces
2. **Monitor resource usage** to identify bottlenecks
3. **Review alert history** for pattern identification
4. **Use operation tracking** to trace specific workflows
5. **Check queue status** for priority and throttling issues

## üìà Performance Optimization

### Batch Size Tuning
- **Small batches (50-100)**: Better for real-time operations
- **Medium batches (200-500)**: Balanced performance and memory
- **Large batches (500-1000)**: Maximum throughput for batch operations

### Concurrency Settings
- **Conservative (2-5 workflows)**: Resource-constrained environments
- **Balanced (5-10 workflows)**: Most production environments
- **Aggressive (10+ workflows)**: High-performance systems

### Memory Optimization
- Configure appropriate batch sizes for available memory
- Use incremental updates when possible
- Enable automatic cleanup of old metrics

### API Rate Limiting
- Adjust API call limits based on Azure DevOps throttling
- Implement backoff strategies for rate limit recovery
- Monitor API usage patterns for optimization

## üß™ Testing

### Integration Tests
Run comprehensive integration tests to validate system functionality:

```bash
# Run all integration tests
python src/datascience_platform/qvf/orchestration/integration_tests.py

# Run with verbose output
python integration_tests.py --verbose

# Run specific test categories
python integration_tests.py --test-category=performance
```

### Performance Testing
```python
# Test with different scales
test_configurations = [
    {"items": 100, "batch_size": 20},    # Small scale
    {"items": 1000, "batch_size": 100},  # Medium scale  
    {"items": 5000, "batch_size": 500},  # Large scale
]

for config in test_configurations:
    # Run performance test with configuration
    result = await run_performance_test(**config)
    print(f"Throughput: {result['throughput']} items/sec")
```

### Load Testing
```python
# Concurrent workflow stress test
async def stress_test():
    tasks = []
    for i in range(10):  # 10 concurrent workflows
        task = orchestrator.score_work_items(
            project_name=f"StressTest_{i}",
            mode=ScoringMode.BATCH,
            criteria_config=qvf_config
        )
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    return results
```

## üîÆ Future Enhancements

### Planned Features
- **Machine Learning Integration**: Predictive scheduling based on historical patterns
- **Multi-Region Support**: Cross-region deployment and data replication
- **GraphQL API**: Advanced query capabilities for monitoring data
- **Kubernetes Integration**: Native container orchestration support
- **Advanced Analytics**: ML-powered anomaly detection and optimization

### Extensibility Points
- **Custom Scorers**: Plugin architecture for specialized scoring algorithms
- **External Integrations**: Webhook support for external system notifications
- **Custom Metrics**: Extensible metrics collection framework
- **Storage Backends**: Support for different persistence layers

## üìù API Reference

### Core Classes

#### QVFOrchestrator
Main orchestration engine for QVF operations.

**Methods:**
- `score_work_items()` - Score work items with specified configuration
- `batch_score_all_items()` - Batch score all eligible items in project
- `incremental_update()` - Update scores for recently changed items
- `schedule_batch_scoring()` - Schedule recurring batch operations
- `get_active_workflows()` - Get currently active workflow information
- `get_operation_statistics()` - Get comprehensive operation statistics
- `validate_system_health()` - Validate system health and readiness

#### QVFScheduler  
Advanced scheduling and priority queue management.

**Methods:**
- `schedule_job()` - Schedule recurring job with cron expression
- `queue_priority_request()` - Queue high-priority scoring request
- `get_scheduled_jobs()` - Get list of scheduled jobs
- `get_queue_status()` - Get current queue status and statistics
- `cancel_job()` - Cancel scheduled job
- `pause_job()` / `resume_job()` - Pause/resume scheduled jobs

#### OperationMonitor
Comprehensive monitoring and performance analytics.

**Methods:**
- `track_operation()` - Context manager for operation tracking
- `get_comprehensive_metrics()` - Get detailed metrics and analysis
- `get_active_operations()` - Get currently active operations
- `add_alert_callback()` - Add callback for alert notifications
- `acknowledge_alert()` - Acknowledge triggered alert

### Enums and Constants

#### ScoringMode
- `REAL_TIME` - Immediate processing
- `BATCH` - Batch processing  
- `INCREMENTAL` - Only changed items
- `FULL_RECALCULATION` - Full portfolio recalculation
- `SCHEDULED` - Scheduled operation

#### OperationPriority
- `LOW` - Low priority (background processing)
- `NORMAL` - Normal priority
- `HIGH` - High priority (expedited processing)
- `URGENT` - Urgent priority (immediate processing)
- `CRITICAL` - Critical priority (highest precedence)

#### WorkflowStatus
- `PENDING` - Workflow queued but not started
- `RUNNING` - Workflow currently executing
- `COMPLETED` - Workflow completed successfully
- `FAILED` - Workflow failed with errors
- `CANCELLED` - Workflow cancelled by user
- `PAUSED` - Workflow paused (for scheduled jobs)

## üìÑ License

This QVF Orchestration System is part of the DataScience Platform and follows the same licensing terms. See the main project LICENSE file for details.

## ü§ù Contributing

1. Follow the existing code style and patterns
2. Add comprehensive tests for new features
3. Update documentation for API changes
4. Ensure backward compatibility when possible
5. Performance test changes with large datasets

## üìû Support

For technical support and questions:
- Review the troubleshooting section above
- Check the integration tests for usage examples
- Examine the comprehensive logging output
- Contact the development team for complex issues

---

*This orchestration system represents a significant advancement in enterprise QVF operations, providing the scalability, reliability, and performance needed for production deployments while maintaining the flexibility for future enhancements.*